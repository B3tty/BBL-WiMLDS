{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Gender Shades](http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf)\n",
    "## Intersectional Accuracy Disparities in Commercial Gender Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Paper contributions \n",
    "\n",
    "\n",
    "* New dataset composed of 1270 individuals, balanced \n",
    "\n",
    "* First Intersectional demographic and phenotypic evaluation of face-based gender classification accuracy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Datasets \n",
    "## 2. Classification \n",
    "## 3. Applications \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why is the dataset important \n",
    "\n",
    "e.g.: Accuracies of face recognition systems used by us law enforcement are systematically lower for people labeled female, black and 18-30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Existing Datasets\n",
    "\n",
    "IJB-A and Adience \n",
    "- Disproportion of representation for gender and phenotypes\n",
    "- Over representation of lighter males \n",
    "- Under representation of darker individuals \n",
    "\n",
    "IJB-A: most geographically diverse set of collected faces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PPB Dataset\n",
    "\n",
    "Pilot Parliaments Benchmark\n",
    "\n",
    "* Dataset balanced by gender and skin type\n",
    "* From parliament pictures \n",
    "* Countries with majority population at opposite ends of the skin type scale \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Challenges\n",
    "\n",
    "* Subjects’ phenotypic features can vary widely within a racial or ethnic category \n",
    "* Racial and ethnic categories are not consistent accross geographies \n",
    "  * Racial and ethnic labels unstable => use skin type \n",
    "* Fitzpatrick classification is skewed towards lighter skin\n",
    "* Gender classifiers provided by companies : gender identity or biological sex? \n",
    "  * PPB labeled as perceived as woman or man\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dataset Labeling \n",
    "\n",
    "Skin type labels\n",
    "* Labeled by the Fitzpatrick six point skin type scale\n",
    "* Board - certified surgical dermatologist provided the definitive labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "Gender labels\n",
    "* Based on name, gendered title, prefixes (Mr, Mrs... ) and appearance on photo \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Algorithms used\n",
    "\n",
    "* 3 commercial gender classifiers: Microsoft, IBM, Face++\n",
    "* Face recognition systems tend to perform better on their respective populations \n",
    "* Microsoft : “advanced statistical algorithms\"\n",
    "* IBM and face++: \"deep learning based algorithms\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test methodology \n",
    "\n",
    "Datasets are only used as testing benchmark.\n",
    "\n",
    "Since proprietary algorithms, can't change training data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test evaluation \n",
    "\n",
    "* Assess overall classification accuracy , male classif accuracy, female classif accuracy (ppv) \n",
    "* Results detailed in more specific groups \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Results\n",
    "\n",
    "* Better performance on male faces than female faces\n",
    "  * 8.1% − 20.6% difference in error rate\n",
    "* Better performance on lighter faces than darker faces\n",
    "  * 11.8% − 19.2% difference in error rate\n",
    "* Worst performance on darker female faces\n",
    "  * 20.8% − 34.7% error rate\n",
    "* Best performance\n",
    "  * Microsoft: lighter male faces (0.0% error rate)\n",
    "  * IBM: lighter male faces (0.3% error rate)\n",
    "  * Face++: darker male faces (0.7% error rate)\n",
    "* The maximum difference in error rate between the best and worst classified groups is 34.4%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples of applications \n",
    "\n",
    "* Helping determine who is hired, fired, granted a loan \n",
    "* How long individual spends in prison \n",
    "* Identify suspects \n",
    "* Identify emotions from images of people's faces\n",
    "* Understand and help people with autism \n",
    "* Surveillance and crime prevention \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions\n",
    "\n",
    "## Discussions \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
